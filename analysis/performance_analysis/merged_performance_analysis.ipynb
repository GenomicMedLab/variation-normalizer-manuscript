{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Normalizer Performance Analysis](#toc0_)\n",
    "\n",
    "This notebook contains an analysis of the normalizer performance on the CIViC, MOA, and Clinvar data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Normalizer Performance Analysis](#toc1_)    \n",
    "  - [Import relevant packages](#toc1_1_)    \n",
    "  - [Dictionaries to map variants to categories and record category counts](#toc1_2_)    \n",
    "  - [CIViC](#toc1_3_)    \n",
    "  - [MOA](#toc1_4_)    \n",
    "  - [ClinVar](#toc1_5_)    \n",
    "  - [Computing Coverage](#toc1_6_)    \n",
    "  - [Generating Table](#toc1_7_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Import relevant packages](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import plotly.graph_objects as go\n",
    "from enum import Enum\n",
    "from enum import IntEnum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Dictionaries to map variants to categories and record category counts](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin variants to categories.\n",
    "\n",
    "For variants with multiple associated types:  If the 2+ types have a subset relationship (eg frameshift; frameshift truncation), they are assigned to categories consistent with the superset type (frameshift).  If the types are disjoint (eg: Transcript Variant; Loss of Function Variant), they are assigned with the category most closely associated with the assayed data (Transcript Variant).  This assignment is done in the civic_category_bins dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_category_bins = {\n",
    "    \"Delins\":\"Sequence Variants\",\n",
    "    \"Direct Tandem Duplication\":\"Sequence Variants\",\n",
    "    \"Disruptive Inframe Deletion\":\"Sequence Variants\",\n",
    "    \"Disruptive Inframe Insertion\":\"Sequence Variants\",\n",
    "    \"Coding Sequence Variant\":\"Sequence Variants\",\n",
    "    \"Conservative Inframe Deletion\":\"Sequence Variants\",\n",
    "    \"Copy Number Variants\":\"Copy Number Variants\",\n",
    "    \"Frameshift\":\"Sequence Variants\",\n",
    "    \"Frameshift Truncation\":\"Sequence Variants\",\n",
    "    \"Frameshift Variant\":\"Sequence Variants\",\n",
    "    \"Frameshift Variant;Minus 1 Frameshift Variant\":\"Sequence Variants\",\n",
    "    \"Inframe Deletion\":\"Sequence Variants\",\n",
    "    \"Inframe Indel\":\"Sequence Variants\",\n",
    "    \"Inframe Insertion\":\"Sequence Variants\",\n",
    "    \"Intron Variant\":\"Region-Defined Variants\",\n",
    "    \"Minus 1 Frameshift Variant\":\"Sequence Variants\",\n",
    "    \"Minus 2 Frameshift Variant\":\"Sequence Variants\",\n",
    "    \"Missense Variant\":\"Sequence Variants\",\n",
    "    \"Non Conservative Missense Variant\":\"Sequence Variants\",\n",
    "    \"Plus 1 Frameshift Variant\":\"Sequence Variants\",\n",
    "    \"Region-Defined Variant\":\"Region-Defined Variants\",\n",
    "    \"Regulatory Region Variant\":\"Region-Defined Variants\",\n",
    "    \"Sequence Variants\":\"Sequence Variants\",\n",
    "    \"Splice Acceptor Variant\":\"Region-Defined Variants\",\n",
    "    \"Splice Donor Region Variant\":\"Region-Defined Variants\",\n",
    "    \"Splice Donor Variant\":\"Region-Defined Variants\",\n",
    "    \"Splicing Variant\":\"Other Variants\",\n",
    "    \"Start Lost\":\"Sequence Variants\",\n",
    "    \"Stop Gained\":\"Sequence Variants\",\n",
    "    \"Stop Lost\":\"Sequence Variants\",\n",
    "    \"Synonymous Variant\":\"Sequence Variants\",\n",
    "    \"Transcript Amplification\":\"Copy Number Variants\",\n",
    "    \"Transcript Fusion\":\"Fusion Variants\",\n",
    "    \"3 Prime UTR Variant\":\"Region-Defined Variants\",\n",
    "    \"Amino Acid Deletion;Inframe Deletion\":\"Sequence Variants\",\n",
    "    \"Frameshift Truncation;Minus 2 Frameshift Variant\":\"Sequence Variants\",\n",
    "    \"Frameshift Truncation;Plus 2 Frameshift Variant\":\"Sequence Variants\",\n",
    "    \"Frameshift Variant;Delins\":\"Sequence Variants\",\n",
    "    \"Inframe Insertion;Delins\":\"Sequence Variants\",\n",
    "    \"Inframe Insertion;Inframe Deletion;Delins\":\"Sequence Variants\",\n",
    "    \"Inframe Variant;Inframe Insertion;Inframe Deletion;Delins \":\"Sequence Variants\",\n",
    "    \"Minus 1 Frameshift Variant;Frameshift Truncation\":\"Sequence Variants\",\n",
    "    \"Plus 1 Frameshift Variant;Frameshift Elongation\":\"Sequence Variants\",\n",
    "    \"Plus 1 Frameshift Variant;Frameshift Truncation\":\"Sequence Variants\",\n",
    "    \"Missense Variant;Gain Of Function Variant\":\"Sequence Variants\", \n",
    "    \"Missense Variant;Loss Of Function Variant\":\"Sequence Variants\", \n",
    "    \"Missense Variant;Loss Of Heterozygosity\":\"Sequence Variants\", \n",
    "    \"Missense Variant;Polymorphic Sequence Variant\":\"Sequence Variants\", \n",
    "    \"Missense Variant;Snp\":\"Sequence Variants\", \n",
    "    \"Missense Variant;Transcript Fusion\":\"Sequence Variants\",\n",
    "    \"Stop Gained;Loss Of Function Variant\":\"Sequence Variants\",\n",
    "    \"Stop Lost;Inframe Deletion\":\"Sequence Variants\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "moa_category_bins = {\n",
    "    \"Copy Number Variants\": \"Copy Number Variants\",\n",
    "    \"Expression Variants\": \"Expression Variants\",\n",
    "    \"Other Variants\": \"Other Variants\",\n",
    "    \"Rearrangement Variants\": \"Rearrangement Variants\",\n",
    "    \"Sequence Variants\": \"Sequence Variants\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "clinvar_category_bins = {\n",
    "    \"Complex\":\"Other Variants\",\n",
    "    \"CompoundHeterozygote\":\"Genotype Variants\",\n",
    "    \"Deletion\":\"Sequence Variants\",\n",
    "    \"Diplotype\":\"Genotype Variants\",\n",
    "    \"Distinct chromosomes\":\"Rearrangement Variants\",\n",
    "    \"Duplication\":\"Sequence Variants\",\n",
    "    \"Haplotype\":\"Sequence Variants\",\n",
    "    \"Haplotype, single variant\":\"Sequence Variants\",\n",
    "    \"Indel\":\"Sequence Variants\",\n",
    "    \"Insertion\":\"Sequence Variants\",\n",
    "    \"Inversion\":\"Sequence Variants\",\n",
    "    \"Microsatellite\":\"Sequence Variants\",\n",
    "    \"Phase unknown\":\"Other Variants\",\n",
    "    \"Tandem duplication\":\"Sequence Variants\",\n",
    "    \"Translocation\":\"Rearrangement Variants\",\n",
    "    \"Variation\":\"Other Variants\",\n",
    "    \"copy number gain\":\"Copy Number Variants\",\n",
    "    \"copy number loss\":\"Copy Number Variants\",\n",
    "    \"fusion\":\"Fusion Variants\",\n",
    "    \"protein only\":\"Sequence Variants\",\n",
    "    \"single nucleotide variant\":\"Sequence Variants\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables flag the fields in the dictionary item values below.  In category_counts, each entry is a list of integer values, representing, in order, the number of tokens normalized of that variant, the number ostensibly supported but unable to be normalized, the number of tokens that are not supported, and the total number of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fields(IntEnum):\n",
    "    \"\"\"Create IntEnum for count fields in the category_counts dict.\"\"\"\n",
    "    NORMALIZED_COUNT = 0\n",
    "    UNABLE_TO_NORMALIZE_COUNT = 1\n",
    "    UNSUPPORTED_COUNT = 2\n",
    "    TOTAL_COUNT = 3\n",
    "    PERCENT_NORMALIZED = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = {\n",
    "    \"Copy Number Variants\":[0,0,0,0,0.0],\n",
    "    \"Epigenetic Modification\":[0,0,0,0,0.0],\n",
    "    \"Expression Variants\":[0,0,0,0,0.0],\n",
    "    \"Fusion Variants\":[0,0,0,0,0.0],\n",
    "    \"Gene Function Variants\":[0,0,0,0,0.0],\n",
    "    \"Genotype Variants\":[0,0,0,0,0.0],\n",
    "    \"Other Variants\":[0,0,0,0,0.0],\n",
    "    \"Rearrangement Variants\":[0,0,0,0,0.0],\n",
    "    \"Region-Defined Variants\":[0,0,0,0,0.0],\n",
    "    \"Sequence Variants\":[0,0,0,0,0.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[CIViC](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to score the normalizer's performance on the CIViC data, some cleaning is required.\n",
    "\n",
    "First we need to read in the data that was ostensibly supported, get rid of variants with multiple type labels, and assign variant types to as  many of the entries as possible that have a \"Not provided\" value for civic_variant_types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in .csv of normalized variants in CIVIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_normalized_df = pd.read_csv(\"../civic/variation_analysis/able_to_normalize_queries.csv\",sep = \"\\t\")\n",
    "civic_normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prune columns and add new column to flag as normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_civic_normalized_df = civic_normalized_df[[\"variant_id\",\"query\",\"query_type\",\"civic_variant_types\"]]\n",
    "pruned_civic_normalized_df.insert(4,\"normalization_status\",\"normalized\")\n",
    "pruned_civic_normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat process with the variants that were unable to be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_not_normalized_df = pd.read_csv(\"../civic/variation_analysis/unable_to_normalize_queries.csv\",sep = \"\\t\")\n",
    "civic_not_normalized_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_civic_not_normalized_df = civic_not_normalized_df[[\"variant_id\",\"query\",\"query_type\",\"civic_variant_types\"]]\n",
    "pruned_civic_not_normalized_df.insert(4,\"normalization_status\",\"not_normalized\")\n",
    "pruned_civic_not_normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge these dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [pruned_civic_normalized_df, pruned_civic_not_normalized_df]\n",
    "civic_supported_df = pd.concat(frames)\n",
    "civic_supported_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making all queries in all caps to make it easier to account of untyped variants later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_supported_df[\"query\"] = civic_supported_df[\"query\"].apply(str.upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking variant types.  The single largest types is \"Not provided\".  \n",
    "Most of these look like amino acid substitutions.\n",
    "Defining a regex to detect these variants and assign \"Missense Variant\" type to these variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_supported_df[\"civic_variant_types\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a variant does not have an assigned variant type in civic, if it is a protein query and the query matches a regex pattern associated with variant substitutions (such as \"PTEN A126D\"), then I am re-classifying them as a \"Missense Variant\" instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_supported_df[\"variant flag\"] = civic_supported_df[\"query\"].apply(lambda x: bool(re.match(\"\\S+\\s+[A-Z]+\\d+[A-Z|*]\", x)))\n",
    "civic_supported_df[\"civic_variant_types\"] = np.where((civic_supported_df[\"query_type\"] == \"protein\") & (civic_supported_df[\"civic_variant_types\"] == \"Not provided\") & (civic_supported_df[\"variant flag\"]), \"Missense Variant\", civic_supported_df[\"civic_variant_types\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing so reduced the 816 untyped variants down to 70.\n",
    "Checking the remaining weird variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untyped_variants = civic_supported_df[civic_supported_df[\"civic_variant_types\"] == \"Not provided\"]\n",
    "untyped_variants.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reassigning variants marked as {gene} Amplification as Transcript Amplification Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_supported_df[\"variant flag\"] = civic_supported_df[\"query\"].apply(lambda x: bool(re.match(\"\\S+\\s+AMPLIFICATION\", x)))\n",
    "civic_supported_df[\"civic_variant_types\"] = np.where((civic_supported_df[\"query_type\"] == \"protein\") & (civic_supported_df[\"civic_variant_types\"] == \"Not provided\") & (civic_supported_df[\"variant flag\"]), \"Transcript Amplification\", civic_supported_df[\"civic_variant_types\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reassigning amino acid insertions, delins, and deletions as \"Missense Variant\", including a couple of variants that have a random space before or after the sequence operation like \"INS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_supported_df[\"variant flag\"] = civic_supported_df[\"query\"].apply(lambda x: bool(re.match(\"\\S+\\s+[A-Z]+\\d+_+[A-Z]+\\d+INS+[A-Z]\", x)))\n",
    "civic_supported_df[\"civic_variant_types\"] = np.where((civic_supported_df[\"query_type\"] == \"protein\") & (civic_supported_df[\"civic_variant_types\"] == \"Not provided\") & (civic_supported_df[\"variant flag\"]), \"Missense Variant\", civic_supported_df[\"civic_variant_types\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_supported_df[\"variant flag\"] = civic_supported_df[\"query\"].apply(lambda x: bool(re.match(\"\\S+\\s+[A-Z]+\\d+_+[A-Z]+\\d+INS+\\s+[A-Z]\", x)))\n",
    "civic_supported_df[\"civic_variant_types\"] = np.where((civic_supported_df[\"query_type\"] == \"protein\") & (civic_supported_df[\"civic_variant_types\"] == \"Not provided\") & (civic_supported_df[\"variant flag\"]), \"Missense Variant\", civic_supported_df[\"civic_variant_types\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_supported_df[\"variant flag\"] = civic_supported_df[\"query\"].apply(lambda x: bool(re.match(\"\\S+\\s+[A-Z]+\\d+-+\\d+\\s+INS+[A-Z]\", x)))\n",
    "civic_supported_df[\"civic_variant_types\"] = np.where((civic_supported_df[\"query_type\"] == \"protein\") & (civic_supported_df[\"civic_variant_types\"] == \"Not provided\") & (civic_supported_df[\"variant flag\"]), \"Missense Variant\", civic_supported_df[\"civic_variant_types\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_supported_df[\"variant flag\"] = civic_supported_df[\"query\"].apply(lambda x: bool(re.match(\"\\S+\\s+[A-Z]+\\d+_+[A-Z]+\\d+DELINS+[A-Z]\", x)))\n",
    "civic_supported_df[\"civic_variant_types\"] = np.where((civic_supported_df[\"query_type\"] == \"protein\") & (civic_supported_df[\"civic_variant_types\"] == \"Not provided\") & (civic_supported_df[\"variant flag\"]), \"Missense Variant\", civic_supported_df[\"civic_variant_types\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_supported_df[\"variant flag\"] = civic_supported_df[\"query\"].apply(lambda x: bool(re.match(\"\\S+\\s+[A-Z]+\\d+_+[A-Z]+\\d+DEL\", x)))\n",
    "civic_supported_df[\"civic_variant_types\"] = np.where((civic_supported_df[\"query_type\"] == \"protein\") & (civic_supported_df[\"civic_variant_types\"] == \"Not provided\") & (civic_supported_df[\"variant flag\"]), \"Missense Variant\", civic_supported_df[\"civic_variant_types\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And assigning missense types to a handful of remaining variants that are non-standard names for genomic and protein sequence variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_supported_df[\"variant flag\"] = civic_supported_df[\"query\"].apply(lambda x: bool(re.match(\"\\S+\\s+P\\.+[A-Z]+\\d+[A-Z]\", x)))\n",
    "civic_supported_df[\"civic_variant_types\"] = np.where((civic_supported_df[\"query_type\"] == \"protein\") & (civic_supported_df[\"civic_variant_types\"] == \"Not provided\") & (civic_supported_df[\"variant flag\"]), \"Missense Variant\", civic_supported_df[\"civic_variant_types\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_supported_df[\"variant flag\"] = civic_supported_df[\"query\"].apply(lambda x: bool(re.match(\"\\S+[A-Z]+\\-+[A-Z]\", x)))\n",
    "civic_supported_df[\"civic_variant_types\"] = np.where((civic_supported_df[\"query_type\"] == \"genomic\") & (civic_supported_df[\"civic_variant_types\"] == \"Not provided\") & (civic_supported_df[\"variant flag\"]), \"Missense Variant\", civic_supported_df[\"civic_variant_types\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_supported_df[\"variant flag\"] = civic_supported_df[\"query\"].apply(lambda x: bool(re.match(\"NC_\\d+\\.+\\d+:[A-Z]+\\.+\\d+[A-Z]+>+[A-Z]\", x)))\n",
    "civic_supported_df[\"civic_variant_types\"] = np.where((civic_supported_df[\"query_type\"] == \"genomic\") & (civic_supported_df[\"civic_variant_types\"] == \"Not provided\") & (civic_supported_df[\"variant flag\"]), \"Missense Variant\", civic_supported_df[\"civic_variant_types\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_supported_df[\"variant flag\"] = civic_supported_df[\"query\"].apply(lambda x: bool(re.match(\"NC_\\d+\\.+\\d+:[A-Z]+\\.+\\d+_+\\d+INS+[A-Z]\", x)))\n",
    "civic_supported_df[\"civic_variant_types\"] = np.where((civic_supported_df[\"query_type\"] == \"genomic\") & (civic_supported_df[\"civic_variant_types\"] == \"Not provided\") & (civic_supported_df[\"variant flag\"]), \"Missense Variant\", civic_supported_df[\"civic_variant_types\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last variant is a unique (to this db) nonstandard nomenclature for just some variant in a particular domain, so it is a region-defined variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_supported_df[\"variant flag\"] = civic_supported_df[\"query\"].apply(lambda x: bool(re.match(\"DICER1 RNASE IIIB MUTATION\", x)))\n",
    "civic_supported_df[\"civic_variant_types\"] = np.where((civic_supported_df[\"query_type\"] == \"protein\") & (civic_supported_df[\"civic_variant_types\"] == \"Not provided\") & (civic_supported_df[\"variant flag\"]), \"Region-Defined Variant\", civic_supported_df[\"civic_variant_types\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add category column to CIViC df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_supported_df[\"category\"] = civic_supported_df[\"civic_variant_types\"].map(civic_category_bins)\n",
    "civic_supported_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split df by normalized/not_normalized flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_normalized_df_cats = civic_supported_df[civic_supported_df[\"normalization_status\"] == \"normalized\"]\n",
    "civic_normalized_df_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_not_normalized_df_cats = civic_supported_df[civic_supported_df[\"normalization_status\"] == \"not_normalized\"]\n",
    "civic_not_normalized_df_cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each df, Get CIViC Variant counts by category and add to counts dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_normalized_category_counts = json.loads(civic_normalized_df_cats[\"category\"].value_counts().to_json())\n",
    "civic_normalized_category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_json_counts(var_category_counts, support_status) -> None:\n",
    "    \"\"\"given a JSON of variant categories and counts and whether that dataframe represents normalized, not_normalized, or not_supported variants, adds the counts of variants to dictionary of counts\n",
    "    \n",
    "    :param var_category_counts: counts of variants in clinvar with variant type information in JSON format.\n",
    "    :param support_status: an int flag to indicate if the variants in the dataframe are normalized (0), unable to be normalized (1), or unsupported (2) by the normalizer\n",
    "    \"\"\"\n",
    "    for category, count in var_category_counts.items():\n",
    "        category_counts[category][support_status] += count\n",
    "        category_counts[category][Fields.total_count] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_json_counts(civic_normalized_category_counts, Fields.NORMALIZED_COUNT)\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_not_normalized_category_counts = json.loads(civic_not_normalized_df_cats[\"category\"].value_counts().to_json())\n",
    "civic_not_normalized_category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_json_counts(civic_not_normalized_category_counts, Fields.UNABLE_TO_NORMALIZE_COUNT)\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the csv for unsupported variants.  This data was already mapped to categories in civic_variant_analysis.  Therefore, we only need to import the data and perform the count on the category column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_supported_variants = pd.read_csv(\"../civic/variation_analysis/not_supported_variants.csv\",sep = \"\\t\")\n",
    "print(not_supported_variants.shape)\n",
    "not_supported_variants.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_supported_variants[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two small discrepancies here. First, there is a hyphen missing from \"Region-Defined Variants\" which will cause a key error.  Second, the variants labelled as \"Transcript Variants\" here should be binned under \"Sequence Variants\".  Fixing that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_supported_variants[\"category\"].replace(\"Region Defined Variants\", \"Region-Defined Variants\", inplace=True)\n",
    "not_supported_variants[\"category\"].replace(\"Transcript Variants\", \"Sequence Variants\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_supported_variants_category_counts = json.loads(not_supported_variants[\"category\"].value_counts().to_json())\n",
    "not_supported_variants_category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_json_counts(not_supported_variants_category_counts, Fields.UNSUPPORTED_COUNT)\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[MOA](#toc0_)\n",
    "\n",
    "Read MOA .csv file for Normalized variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moa_normalized_df = pd.read_csv(\"../moa/feature_analysis/able_to_normalize_queries.csv\",sep = \"\\t\")\n",
    "print(moa_normalized_df.shape)\n",
    "moa_normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get variant counts by category, update variant counts df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moa_normalized_category_counts = json.loads(moa_normalized_df[\"category\"].value_counts().to_json())\n",
    "moa_normalized_category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_json_counts(moa_normalized_category_counts, Fields.NORMALIZED_COUNT)\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat same process for variants that were supported but failed to normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moa_not_normalized_df = pd.read_csv(\"../moa/feature_analysis/unable_to_normalize_queries.csv\",sep = \"\\t\")\n",
    "print(moa_not_normalized_df.shape)\n",
    "moa_not_normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moa_not_normalized_category_counts = json.loads(moa_not_normalized_df[\"category\"].value_counts().to_json())\n",
    "moa_not_normalized_category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_json_counts(moa_not_normalized_category_counts, Fields.UNABLE_TO_NORMALIZE_COUNT)\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat same process for variants that are unsupported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moa_not_supported_df = pd.read_csv(\"../moa/feature_analysis/not_supported_variants.csv\",sep = \"\\t\")\n",
    "print(moa_not_supported_df.shape)\n",
    "print(moa_not_supported_df.head())\n",
    "moa_not_supported_df[\"category\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moa_not_supported_category_counts = json.loads(moa_not_supported_df[\"category\"].value_counts().to_json())\n",
    "moa_not_supported_category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_json_counts(moa_not_supported_category_counts, Fields.UNSUPPORTED_COUNT)\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[ClinVar](#toc0_)\n",
    "\n",
    "Read in the three clinvar csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_normalized_df = pd.read_csv(\"../clinvar/clinvar_variation_analysis_output/variation_type_count_supported_df.csv\")\n",
    "print(clinvar_normalized_df.shape)\n",
    "clinvar_normalized_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_not_normalized_df = pd.read_csv(\"../clinvar/clinvar_variation_analysis_output/variation_type_count_supported_not_normalized_df.csv\")\n",
    "print(clinvar_not_normalized_df.shape)\n",
    "clinvar_not_normalized_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_not_supported_df = pd.read_csv(\"../clinvar/clinvar_variation_analysis_output/variation_type_count_not_supported_df.csv\")\n",
    "print(clinvar_not_supported_df.shape)\n",
    "clinvar_not_supported_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add column and map variant types to categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_normalized_df[\"category\"] = clinvar_normalized_df[\"in.variation_type\"].map(clinvar_category_bins)\n",
    "clinvar_normalized_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_not_normalized_df[\"category\"] = clinvar_not_normalized_df[\"in.variation_type\"].map(clinvar_category_bins)\n",
    "clinvar_not_normalized_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_not_supported_df[\"category\"] = clinvar_not_supported_df[\"in.variation_type\"].map(clinvar_category_bins)\n",
    "clinvar_not_supported_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the structure of the data and the way that the original analysis developed, some but not all CNVs per the in.variation_type were annotated in the in.vrs_xform_plan.policy column as \"Copy number change (cn loss|del and cn gain|dup)\", \"Absolute copy count\", or \"Min/max copy count range not supported\".  However, some of the Copy number Gain/Loss variants did not get binned as CNVs per the in.vrs_xform_plan.policy.  Therefore, we need to mark those variants in the union of the following two sets as being in the category of Copy Number Variants:\n",
    "\n",
    "Variants with in.variant_type ==\n",
    "1. copy number loss\n",
    "2. copy number gain\n",
    "\n",
    "Variants with in.vrs_xform_plan.policy == \n",
    "1. Copy number change (cn loss|del and cn gain|dup)\n",
    "2. Absolute copy count\n",
    "3. Min/max copy count range not supported\n",
    "\n",
    "Above we already caught the first set of variants. Now we must go back through each df one more time and map the variants we missed per in.vrs_xform_plan.policy values to the category of Copy Number Variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnv_per_policy = [\"Copy number change (cn loss|del and cn gain|dup)\",\"Absolute copy count\",\"Min/max copy count range not supported\",\"Copy number change (cn loss|del and cn gain|dup)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_normalized_df.loc[\n",
    "    clinvar_normalized_df[\"in.vrs_xform_plan.policy\"].isin(cnv_per_policy),\n",
    "      \"category\"\n",
    "      ] = \"Copy Number Variants\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_not_normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_not_normalized_df.loc[\n",
    "    clinvar_not_normalized_df[\"in.vrs_xform_plan.policy\"].isin(cnv_per_policy),\n",
    "      \"category\"\n",
    "      ] = \"Copy Number Variants\"\n",
    "\n",
    "\n",
    "clinvar_not_normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_not_supported_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_not_supported_df.loc[\n",
    "    clinvar_not_supported_df[\"in.vrs_xform_plan.policy\"].isin(cnv_per_policy),\n",
    "      \"category\"\n",
    "      ] = \"Copy Number Variants\"\n",
    "\n",
    "clinvar_not_supported_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get counts from the three dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_clinvar_counts(dataframe: pd.DataFrame, support_status: int) -> None:\n",
    "    \"\"\"given a dataframe and whether that dataframe represents normalized, not_normalized, or not_supported variants, adds the counts of variants to dictionary of counts\n",
    "    \n",
    "    :param dataframe: counts of variants in clinvar with variant type information in dataframe format.\n",
    "    :param support_status: an int flag to indicate if the variants in the dataframe are normalized (0), unable to be normalized (1), or unsupported (2) by the normalizer\n",
    "    \"\"\"\n",
    "    for i in category_counts.keys():\n",
    "        subdf = dataframe[dataframe[\"category\"] == i]\n",
    "        if len(subdf):\n",
    "            category = i\n",
    "            count = subdf[\"count\"].sum()\n",
    "            print(category, count)\n",
    "            category_counts[category][support_status] += count\n",
    "            category_counts[category][Fields.TOTAL_COUNT] += count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_clinvar_counts(clinvar_normalized_df,Fields.NORMALIZED_COUNT)\n",
    "\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_clinvar_counts(clinvar_not_normalized_df,Fields.UNABLE_TO_NORMALIZE_COUNT)\n",
    "\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_clinvar_counts(clinvar_not_supported_df,Fields.UNSUPPORTED_COUNT)\n",
    "\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Computing Coverage](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of making the table, computing the percent of all variants normalized in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in category_counts.keys():\n",
    "    normalized = category_counts[i][Fields.NORMALIZED_COUNT]\n",
    "    total = category_counts[i][Fields.TOTAL_COUNT]\n",
    "    percent_covered = normalized/total\n",
    "    category_counts[i][Fields.percent_normalized] = \"%.4f\" % percent_covered\n",
    "\n",
    "category_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_7_'></a>[Generating Table](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a table in plotly to show variant counts and normalization percentage by category, as well as the types of data fields associated with different variant categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariantCategory(str, Enum):\n",
    "    \"\"\"Create enum for the kind of variants that are in the combined analysis.\"\"\"\n",
    "    SEQUENCE_VARS = \"Sequence Variants\"\n",
    "    GENOTYPES = \"Genotype Variants\"\n",
    "    FUSION = \"Fusion Variants\"\n",
    "    REARRANGEMENTS = \"Rearrangement Variants\"\n",
    "    EPIGENETIC_MODIFICATION = \"Epigenetic Modification\"\n",
    "    COPY_NUMBER = \"Copy Number Variants\"\n",
    "    EXPRESSION = \"Expression Variants\"\n",
    "    GENE_FUNC = \"Gene Function Variants\"\n",
    "    REGION_DEFINED_VAR = \"Region-Defined Variants\"\n",
    "    OTHER = \"Other Variants\"\n",
    "\n",
    "VARIANT_CATEGORY_VALUES = VariantCategory.__members__.values()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_colors = ['rgb(49, 130, 189)','rgb(239, 243, 255)', 'rgb(189, 215, 231)', 'rgb(107, 174, 214)',\n",
    "           'white']\n",
    "core_field = \"\\u2B24\"\n",
    "optional_field = \"<b>◯</b>\"\n",
    "\n",
    "colors = ['rgb(49, 130, 189)','white', 'white', 'white',\n",
    "           'white', 'rgb(49, 130, 189)', 'white', 'white', 'rgb(189, 215, 231)','rgb(107, 174, 214)']\n",
    "data = {'variant_category' : VARIANT_CATEGORY_VALUES,\n",
    "        'counts' : [f'{category_counts[v.value][Fields.TOTAL_COUNT]:,}' for v in VARIANT_CATEGORY_VALUES],\n",
    "        'percent_normalized' : [\"%.2f\" %round(float(category_counts[v.value][Fields.PERCENT_NORMALIZED])*100,2)+\"%\" for v in VARIANT_CATEGORY_VALUES],\n",
    "        'delta_sequence' : [core_field, core_field, \"\", \"\", \"\", \"\", \"\", \"\", \"\", optional_field],\n",
    "        'delta_location' : [optional_field, optional_field, core_field, core_field, \"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "        'delta_frame' : [optional_field, optional_field, \"\", \"\", \"\", \"\", \"\", \"\", \"\", optional_field],\n",
    "        'delta_quantity' : [optional_field, optional_field, \"\", \"\", core_field, core_field, optional_field, \"\", \"\", optional_field],\n",
    "        'delta_function' : [optional_field, optional_field, \"\", \"\", optional_field, optional_field, core_field, core_field, \"\", optional_field],\n",
    "        'region_specificity' : [optional_field, optional_field, optional_field, optional_field, optional_field, optional_field, optional_field, optional_field, core_field, optional_field],\n",
    "        'shading' : colors\n",
    "         }\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "fig = go.Figure(data=[go.Table(\n",
    "  columnwidth = [90,53,65,53,50,50,50,50,50,50],\n",
    "  header=dict(\n",
    "    values=[\"<b>Variant Category</b>\", \"<b>Count</b>\", \"<b>% Normalized</b>\", \"<b>Δ Sequence</b>\", \"<b>Δ Location</b>\", \"<b>Δ Frame</b>\", \"<b>Δ Quantity</b>\", \"<b>Δ Function</b>\", \"<b>Region Specificity</b>\"],\n",
    "    line_color='black', fill_color='white',\n",
    "    align='center', font=dict(color='black', size=18)\n",
    "  ),\n",
    "  cells=dict(\n",
    "    values=[df.variant_category, df.counts, df.percent_normalized, df.delta_sequence, df.delta_location, df.delta_frame, df.delta_quantity, df.delta_function, df.region_specificity],\n",
    "    line_color=[\"black\"], fill_color= [df.shading],\n",
    "    align='right', font=dict(color='black', size=18), height=30\n",
    "  ))\n",
    "\n",
    "])\n",
    "\n",
    "fig.add_annotation(\n",
    "            dict(\n",
    "                text='  \\u2B24  Core information fields<br><br>  <b>◯</b>  Optional information fields  ',\n",
    "                align='left',\n",
    "                showarrow=False,\n",
    "                xref='paper',\n",
    "                xanchor = 'right',\n",
    "                yref='paper',\n",
    "                x=0.98,\n",
    "                y=0.02,\n",
    "                yanchor = 'bottom',\n",
    "                bordercolor='black',\n",
    "                borderwidth=1\n",
    "            ))\n",
    "\n",
    "fig.update_layout(\n",
    "    height=585, \n",
    "    width=1400,\n",
    "    font=dict(\n",
    "        size=18,\n",
    "        color=\"Black\"\n",
    "        ),\n",
    "    title = \"<b>Counts, Normalizer Performance, and Data Types of Variants by Category</b>\",\n",
    "        margin=go.layout.Margin(\n",
    "        l=2, #left margin\n",
    "        r=2, #right margin\n",
    "        b=0, #bottom margin\n",
    "        t=52  #top margin\n",
    "    ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the table as a .png file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"../merged_performance_analysis_table.png\",'png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
