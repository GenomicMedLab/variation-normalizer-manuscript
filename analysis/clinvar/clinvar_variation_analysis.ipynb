{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[ClinVar Variant Analysis](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clinvar_variation_analysis notebook contains an analysis on ClinVar variant data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [ClinVar Variant Analysis](#toc1_)    \n",
    "  - [Initialize](#toc1_1_)    \n",
    "    - [Import necessary libraries](#toc1_1_1_)    \n",
    "    - [Create output directory](#toc1_1_2_)    \n",
    "    - [Import variant information file](#toc1_1_3_)    \n",
    "  - [Add Supported Status of Variant based on in.vrs_xform_plan.policy](#toc1_2_)    \n",
    "  - [Add Normalization Status of Variant based on out.errors](#toc1_3_)    \n",
    "    - [Set Normalize Status of Variant as T/F](#toc1_3_1_)    \n",
    "      - [Summary Table](#toc1_3_1_1_)    \n",
    "  - [Create subgroups based on Variant Status](#toc1_4_)    \n",
    "    - [Supported and Normalized Variants](#toc1_4_1_)    \n",
    "    - [Supported and Not Normalized Variants](#toc1_4_2_)    \n",
    "    - [Not Supported Variants](#toc1_4_3_)    \n",
    "  - [Counting variants from each group](#toc1_5_)    \n",
    "  - [Counting variant types for each group](#toc1_6_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Initialize](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Import necessary libraries](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndjson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import boto3\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[Create output directory](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"variation_analysis_output\")\n",
    "path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_3_'></a>[Import variant information file](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out this cell if the file already exists in the variation_analysis_output folder\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "with open(\"../clinvar/output-variation_identity-vrs-1.3.ndjson.gz\", \"wb\") as data:\n",
    "    s3.download_fileobj(\n",
    "        \"nch-igm-wagner-lab-public\",\n",
    "        \"variation-normalizer-manuscript/output-variation_identity-vrs-1.3.ndjson.gz\",\n",
    "        data,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"output-variation_identity-vrs-1.3.ndjson.gz\", \"rb\") as f: file_content = ndjson.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(file_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Add Supported Status of Variant based on in.vrs_xform_plan.policy](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"in.vrs_xform_plan.policy\"] = df[\"in.vrs_xform_plan.policy\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"in.vrs_xform_plan.policy\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"support_status\"] = df[\"in.vrs_xform_plan.policy\"].copy()\n",
    "\n",
    "df.loc[df[\"support_status\"] == \"Canonical SPDI\", \"support_status\"] = True\n",
    "df.loc[df[\"support_status\"] == \"Absolute copy count\", \"support_status\"] = True\n",
    "df.loc[\n",
    "    df[\"support_status\"] == \"Copy number change (cn loss|del and cn gain|dup)\",\n",
    "    \"support_status\",\n",
    "] = True\n",
    "df.loc[df[\"support_status\"] == \"NCBI36 genomic only\", \"support_status\"] = False\n",
    "df.loc[df[\"support_status\"] == \"No hgvs or location info\", \"support_status\"] = False\n",
    "df.loc[df[\"support_status\"] == \"Genotype/Haplotype\", \"support_status\"] = False\n",
    "df.loc[df[\"support_status\"] == \"Invalid/unsupported hgvs\", \"support_status\"] = False\n",
    "df.loc[df[\"support_status\"] == \"Remaining valid hgvs alleles\", \"support_status\"] = True\n",
    "df.loc[\n",
    "    df[\"support_status\"] == \"Min/max copy count range not supported\", \"support_status\"\n",
    "] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"support_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Add Normalization Status of Variant based on out.errors](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The errors are stored as a list of values, some of which are strings and other of which are dictionaries (determined by whether error was handled at the level of Variation Normalizer or after the normalizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"get_errors\" function extracts the text error responses for better readability and ease string processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors(errors: list) -> str:\n",
    "    \"\"\"Takes the values for the errors and represents them as a string\n",
    "    :param errors: list of errors\n",
    "    :return: string representing error\n",
    "    \"\"\"\n",
    "    errors_out = []\n",
    "    for e in errors:\n",
    "        if isinstance(e, str):\n",
    "            errors_out.append(e)\n",
    "        elif isinstance(e, dict):\n",
    "            for k, v in e.items():\n",
    "                if k not in [\"msg\", \"response-errors\"]:\n",
    "                    ## only get these keys from normalizer response\n",
    "                    continue\n",
    "                if isinstance(v, str):\n",
    "                    errors_out.append(v)\n",
    "                elif isinstance(e, list):\n",
    "                    errors_out.append(\";\".join(v))\n",
    "    return \";\".join(errors_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"error_string\"] = df[\"out.errors\"].fillna(\"\").apply(get_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"error_string\"] = df[\"error_string\"].replace(\"\", \"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"error_string\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are Not Supported variants that have no error (marked as success inaccurately) because they were labeled \"Not Supported\" manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An error (\"Not Supported\") is entered manually for those variants so that they are not categorized as normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\n",
    "    (~df[\"support_status\"]) & (df[\"error_string\"] == \"Success\"),\n",
    "    \"error_string\",\n",
    "] = \"Not Supported\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_1_'></a>[Set Normalize Status of Variant as T/F](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an error is present, the variant was not normalized and therefore has a False Normalize Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"normalize_status\"] = df[\"error_string\"] == \"Success\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_1_1_'></a>[Summary Table](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table below, the cells show the number of variants with each expected behavior and how they actually ended up performing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a variant was in an \"expected to pass\" category and ends up as text, that is an instance of a normalizer failure on a supported variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = (\n",
    "    df[[\"in.id\", \"support_status\", \"in.vrs_xform_plan.policy\", \"out.type\"]]\n",
    "    .fillna(\"NONE\")\n",
    "    .groupby([\"support_status\", \"in.vrs_xform_plan.policy\", \"out.type\"])\n",
    "    .count()\n",
    "    .unstack(level=2)\n",
    "    .fillna(0)\n",
    "    .astype(int)[\"in.id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df[\"VariantSum\"] = summary_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df[\"NormalizedSum\"] = summary_df[\n",
    "    [\"Allele\", \"CopyNumberChange\", \"CopyNumberCount\"]\n",
    "].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df[\"NormalizedPercent\"] = (\n",
    "    summary_df[\"NormalizedSum\"] / summary_df[\"VariantSum\"]\n",
    ").apply(lambda x: f\"{round(x * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = summary_df.drop([\"VariantSum\", \"NormalizedSum\"], axis=1)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_csv(\"variation_analysis_output/variant_analysis_summary_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Create subgroups based on Variant Status](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_1_'></a>[Supported and Normalized Variants](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_df = supported_df.loc[\n",
    "    (supported_df[\"support_status\"] & supported_df[\"normalize_status\"])\n",
    "]\n",
    "supported_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_type_count_supported_df = (\n",
    "    supported_df[[\"in.id\", \"in.variation_type\"]].groupby(\"in.variation_type\").count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_type_count_supported_df.to_csv(\n",
    "    \"variation_analysis_output/variation_type_count_supported_df.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_2_'></a>[Supported and Not Normalized Variants](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_not_normalized_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_not_normalized_df = supported_not_normalized_df.loc[\n",
    "    (\n",
    "        supported_not_normalized_df[\"support_status\"]\n",
    "        & ~supported_not_normalized_df[\"normalize_status\"]\n",
    "    )\n",
    "]\n",
    "supported_not_normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_type_count_supported_not_normalized_df = (\n",
    "    supported_not_normalized_df[[\"in.id\", \"in.variation_type\"]]\n",
    "    .groupby(\"in.variation_type\")\n",
    "    .count()\n",
    ")\n",
    "variation_type_count_supported_not_normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_type_count_supported_not_normalized_df.to_csv(\n",
    "    \"variation_analysis_output/variation_type_count_supported_not_normalized_df.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_3_'></a>[Not Supported Variants](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_supported_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_supported_df = not_supported_df.loc[\n",
    "    ~not_supported_df[\"support_status\"] & ~not_supported_df[\"normalize_status\"]\n",
    "]\n",
    "not_supported_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_type_count_not_supported_df = (\n",
    "    not_supported_df[[\"in.id\", \"in.variation_type\"]]\n",
    "    .groupby(\"in.variation_type\")\n",
    "    .count()\n",
    ")\n",
    "variation_type_count_not_supported_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_type_count_not_supported_df.to_csv(\n",
    "    \"variation_analysis_output/variation_type_count_not_supported_df.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: making sure there are no supported variants that have been marked as normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_supported_but_normalized_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_supported_but_normalized_df = not_supported_but_normalized_df.loc[\n",
    "    (\n",
    "        ~not_supported_but_normalized_df[\"support_status\"]\n",
    "        & not_supported_but_normalized_df[\"normalize_status\"]\n",
    "    )\n",
    "]\n",
    "not_supported_but_normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Counting variants from each group](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_supported = len(supported_df)\n",
    "num_supported_not_normalized = len(supported_not_normalized_df)\n",
    "num_not_supported_but_normalized = len(not_supported_but_normalized_df)\n",
    "num_not_supported = len(not_supported_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"Supported\": [num_supported, num_supported_not_normalized],\n",
    "        \"Not Supported\": [num_not_supported_but_normalized, num_not_supported],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df2.index = [\"Normalized\", \"Not Normalized\"]\n",
    "summary_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Counting variant types for each group](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_type_count_summary_df = pd.merge(\n",
    "    pd.merge(\n",
    "        variation_type_count_supported_df,\n",
    "        variation_type_count_supported_not_normalized_df,\n",
    "        on=\"in.variation_type\",\n",
    "        how=\"left\",\n",
    "    ),\n",
    "    variation_type_count_not_supported_df,\n",
    "    on=\"in.variation_type\",\n",
    "    how=\"right\",\n",
    ")\n",
    "variation_type_count_summary_df = variation_type_count_summary_df.replace(\n",
    "    np.nan, 0, regex=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_type_count_summary_df = variation_type_count_summary_df.rename(\n",
    "    columns={\n",
    "        \"in.id_x\": \"supported\",\n",
    "        \"in.id_y\": \"supported_not_normalized\",\n",
    "        \"in.id\": \"not_supported\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_type_count_summary_df.to_csv(\n",
    "    \"variation_analysis_output/variation_type_count_summary_df.csv\"\n",
    ")\n",
    "variation_type_count_summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60bedfc6dd95a1d756c285a8080496495ec396023cb257f004626f94ae504b38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
