{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENIE Pre Variant Analysis\n",
    "\n",
    "This data uses `data_mutations_extended.txt` from Synapse. You will need to create an account to download data from [here](https://www.synapse.org/#!Synapse:syn51355986). This notebook expects the `data_mutations_extended.txt` to be in the same directory.\n",
    "\n",
    "This notebook is used to run GENIE variant data through the variation-normalizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-e git+https://github.com/cancervariants/variation-normalization.git@8b2e582b0a2bb2f6636da2d75ecabffc1388cda6#egg=variation_normalizer\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kxk102/Documents/genomic_med_lab/folder-migration/variation-normalizer-manuscript/.venv/lib/python3.11/site-packages/python_jsonschema_objects/__init__.py:49: UserWarning: Schema version http://json-schema.org/draft-07/schema not recognized. Some keywords and features may not be supported.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import logging\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from variation.query import QueryHandler\n",
    "from variation.schemas.service_schema import ClinVarAssembly\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.getLogger(\"root\").setLevel(logging.WARNING)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lf/5g499lhn423dlt_l3y1ctkv0drnwj5/T/ipykernel_4477/3094103739.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  genie_variants_df = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1219725, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get GENIE Variant data\n",
    "genie_variants_df = pd.read_csv(\n",
    "    \"data_mutations_extended.txt\", sep=\"\\t\",\n",
    "    usecols=[\n",
    "        \"Hugo_Symbol\", \n",
    "        \"NCBI_Build\",\n",
    "        \"Chromosome\", \n",
    "        \"Start_Position\", \n",
    "        \"End_Position\", \n",
    "        \"Reference_Allele\",\n",
    "        \"Tumor_Seq_Allele2\", \n",
    "        \"HGVSp_Short\",\n",
    "        \"dbSNP_RS\"\n",
    "    ]\n",
    ")\n",
    "# Some positions are '-', we drop nan below\n",
    "genie_variants_df = genie_variants_df.replace({\"-\": np.nan})\n",
    "\n",
    "genie_variants_df[\"free_text_p_short\"] = np.where(\n",
    "    ~genie_variants_df[\"Hugo_Symbol\"].isna() & ~genie_variants_df[\"HGVSp_Short\"].isna(),\n",
    "    genie_variants_df[\"Hugo_Symbol\"] + \" \" + genie_variants_df[\"HGVSp_Short\"],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "genie_variants_df[\"coordinates\"] = np.where(\n",
    "    ~genie_variants_df[\"Chromosome\"].isna() & ~genie_variants_df[\"Start_Position\"].isna() & ~genie_variants_df[\"End_Position\"].isna() & ~genie_variants_df[\"Reference_Allele\"].isna() & ~genie_variants_df[\"Tumor_Seq_Allele2\"].isna() & ~genie_variants_df[\"NCBI_Build\"].isna(),\n",
    "    genie_variants_df[\"Chromosome\"].astype(str) + \"-\" + genie_variants_df[\"Start_Position\"].astype(str) + \"-\" + genie_variants_df[\"Reference_Allele\"] + \"-\" + genie_variants_df[\"Tumor_Seq_Allele2\"],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "genie_variants_df = genie_variants_df[genie_variants_df[\"free_text_p_short\"].notna()]\n",
    "genie_variants_df = genie_variants_df[genie_variants_df[\"coordinates\"].notna()]\n",
    "genie_variants_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "path = Path(\"variation_normalizer_output\")\n",
    "path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Protein (free text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1219725, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "free_text_df = genie_variants_df.copy()\n",
    "free_text_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(588395, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "free_text_df = free_text_df.drop_duplicates(subset=[\"free_text_p_short\"])\n",
    "free_text_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create free text df csv (if we need to debug)\n",
    "free_text_df.to_csv(\"variation_normalizer_output/free_text_df.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_text_queries = [v for v in free_text_df[\"free_text_p_short\"].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genomic (coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1219725, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates_df = genie_variants_df.copy()\n",
    "coordinates_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639707, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "coordinates_df = coordinates_df.drop_duplicates(subset=[\"coordinates\"])\n",
    "coordinates_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create coordinates df csv (if we need to debug)\n",
    "coordinates_df.to_csv(\"variation_normalizer_output/coordinates_df.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_queries = [v for v in coordinates_df[\"coordinates\"].values]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try using /normalize\n",
    "\n",
    "In this section, we will run the queries through the variation normalizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Environment variables are set for gene-normalizer dynamodb instance and \n",
    "# UTA DB credentials\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Using Gene Database Endpoint: http://localhost:8000***\n"
     ]
    }
   ],
   "source": [
    "query_handler = QueryHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_from_genomic(genomic_query: str) -> dict:\n",
    "    \"\"\"Try using vrs-python translate from using genomic query that failed to normalize\"\"\"\n",
    "    resp = {\n",
    "        \"vrs_id\": None,\n",
    "        \"error\": None\n",
    "    }\n",
    "    try:\n",
    "        translate_from_resp = query_handler.vrs_python_tlr.translate_from(genomic_query, assembly_name=\"GRCh37\")\n",
    "    except Exception as e:\n",
    "        resp[\"error\"] = str(e)\n",
    "    else:\n",
    "        resp[\"vrs_id\"] = translate_from_resp._id._value\n",
    "\n",
    "    return resp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def normalize_genie(queries: list[str], query_type: str):\n",
    "    # This file contains GENIE Variant queries that we were not able to normalize.\n",
    "    unable_to_normalize_wf = open(f\"variation_normalizer_output/unable_to_normalize_{query_type}_queries.csv\", \"w\")\n",
    "    unable_to_normalize_wr = csv.writer(unable_to_normalize_wf, delimiter=\"\\t\")\n",
    "    unable_to_normalize_wr.writerow([\"query\", \"exception_raised\", \"message\", \"warnings\"])\n",
    "\n",
    "    # This file contains GENIE Variant queries that we were able to normalize.\n",
    "    able_to_normalize_wf = open(f\"variation_normalizer_output/able_to_normalize_{query_type}_queries.csv\", \"w\")\n",
    "    able_to_normalize_wr = csv.writer(able_to_normalize_wf, delimiter=\"\\t\")\n",
    "    able_to_normalize_wr.writerow([\"query\", \"vrs_id\", \"succeeded_endpoint\"])\n",
    "\n",
    "    for query in tqdm(queries):\n",
    "        try:\n",
    "            variation_norm_resp = await query_handler.normalize_handler.normalize(query, input_assembly=ClinVarAssembly.GRCH37)\n",
    "        except Exception as e:\n",
    "            warnings = [str(e)]\n",
    "\n",
    "            if query_type == \"genomic\":\n",
    "                genomic_resp = translate_from_genomic(query)\n",
    "\n",
    "                if genomic_resp[\"vrs_id\"]:\n",
    "                    vrs_id = genomic_resp[\"vrs_id\"]\n",
    "                else:\n",
    "                    vrs_id = None\n",
    "                    warnings.append(genomic_resp[\"error\"])\n",
    "\n",
    "                if vrs_id:\n",
    "                    able_to_normalize_wr.writerow([query, vrs_id, \"translate_from\"])\n",
    "                    continue\n",
    "            \n",
    "            unable_to_normalize_wr.writerow([query, True, str(e), None])\n",
    "        else:\n",
    "            if variation_norm_resp.variation_descriptor:\n",
    "                vrs_id = variation_norm_resp.variation_descriptor.variation.id\n",
    "                able_to_normalize_wr.writerow([query, vrs_id, \"normalize\"])\n",
    "            else:\n",
    "                warnings = sorted(variation_norm_resp.warnings)\n",
    "                if query_type == \"genomic\":\n",
    "                    genomic_resp = translate_from_genomic(query)\n",
    "\n",
    "                    if genomic_resp[\"vrs_id\"]:\n",
    "                        vrs_id = genomic_resp[\"vrs_id\"]\n",
    "                    else:\n",
    "                        vrs_id = None\n",
    "                        warnings.append(genomic_resp[\"error\"])\n",
    "\n",
    "                    if vrs_id:\n",
    "                        able_to_normalize_wr.writerow([query, vrs_id, \"translate_from\"])\n",
    "                        continue\n",
    "\n",
    "                unable_to_normalize_wr.writerow(\n",
    "                    [query, False, \"unable to normalize\", warnings]\n",
    "                )\n",
    "\n",
    "    # Close all files\n",
    "    unable_to_normalize_wf.close()\n",
    "    able_to_normalize_wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 588395/588395 [48:59:57<00:00,  3.34it/s]    \n"
     ]
    }
   ],
   "source": [
    "await normalize_genie(free_text_queries, \"protein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 639707/639707 [1:52:21<00:00, 94.89it/s]   \n"
     ]
    }
   ],
   "source": [
    "await normalize_genie(coordinates_queries, \"genomic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
