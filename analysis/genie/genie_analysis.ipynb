{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENIE Analysis\n",
    "\n",
    "This data uses `data_mutations_extended.txt` from Synapse. You will need to create an account to download data from [here](https://www.synapse.org/#!Synapse:syn51355986). This notebook expects the `data_mutations_extended.txt` to be in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from variation.query import QueryHandler\n",
    "from variation.schemas.service_schema import ClinVarAssembly\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.getLogger(\"root\").setLevel(logging.WARNING)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GENIE Variant data\n",
    "genie_variants_df = pd.read_csv(\n",
    "    \"data_mutations_extended.txt\", sep=\"\\t\",\n",
    "    usecols=[\n",
    "        \"Hugo_Symbol\", \n",
    "        \"NCBI_Build\",\n",
    "        \"Chromosome\", \n",
    "        \"Start_Position\", \n",
    "        \"End_Position\", \n",
    "        \"Reference_Allele\",\n",
    "        \"Tumor_Seq_Allele2\", \n",
    "        \"HGVSp_Short\",\n",
    "        \"dbSNP_RS\"\n",
    "    ]\n",
    ")\n",
    "# Some positions are '-', we drop nan below\n",
    "genie_variants_df = genie_variants_df.replace({\"-\": np.nan})\n",
    "\n",
    "genie_variants_df[\"free_text_p_short\"] = np.where(\n",
    "    ~genie_variants_df[\"Hugo_Symbol\"].isna() & ~genie_variants_df[\"HGVSp_Short\"].isna(),\n",
    "    genie_variants_df[\"Hugo_Symbol\"] + \" \" + genie_variants_df[\"HGVSp_Short\"],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "genie_variants_df[\"coordinates\"] = np.where(\n",
    "    ~genie_variants_df[\"Chromosome\"].isna() & ~genie_variants_df[\"Start_Position\"].isna() & ~genie_variants_df[\"End_Position\"].isna() & ~genie_variants_df[\"Reference_Allele\"].isna() & ~genie_variants_df[\"Tumor_Seq_Allele2\"].isna() & ~genie_variants_df[\"NCBI_Build\"].isna(),\n",
    "    genie_variants_df[\"Chromosome\"].astype(str) + \"-\" + genie_variants_df[\"Start_Position\"].astype(str) + \"-\" + genie_variants_df[\"Reference_Allele\"] + \"-\" + genie_variants_df[\"Tumor_Seq_Allele2\"],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "genie_variants_df = genie_variants_df[genie_variants_df[\"free_text_p_short\"].notna()]\n",
    "genie_variants_df = genie_variants_df[genie_variants_df[\"coordinates\"].notna()]\n",
    "genie_variants_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_text_df = genie_variants_df[\"free_text_p_short\"].copy()\n",
    "free_text_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get duplicates\n",
    "free_text_dups = free_text_df.loc[free_text_df.duplicated()]\n",
    "free_text_dups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop duplicates\n",
    "free_text_df = free_text_df.drop_duplicates()\n",
    "free_text_queries = [v for v in free_text_df.values]\n",
    "len(free_text_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_df = genie_variants_df[\"coordinates\"].copy()\n",
    "coordinates_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get duplicates\n",
    "coord_dups = coordinates_df.loc[coordinates_df.duplicated()]\n",
    "coord_dups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop duplicates\n",
    "coordinates_df = coordinates_df.drop_duplicates()\n",
    "coordinate_queries = [v for v in coordinates_df.values]\n",
    "len(coordinate_queries)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try using /normalize\n",
    "\n",
    "In this section, we will run the queries through the variation normalizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables are set for gene-normalizer dynamodb instance and \n",
    "# UTA DB credentials\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_handler = QueryHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_from_genomic(genomic_query: str) -> dict:\n",
    "    \"\"\"Try using vrs-python translate from using genomic query that failed to normalize\"\"\"\n",
    "    resp = {\n",
    "        \"vrs_id\": None,\n",
    "        \"error\": None\n",
    "    }\n",
    "    try:\n",
    "        translate_from_resp = query_handler.vrs_python_tlr.translate_from(genomic_query, assembly_name=\"GRCh37\")\n",
    "    except Exception as e:\n",
    "        resp[\"error\"] = str(e)\n",
    "    else:\n",
    "        resp[\"vrs_id\"] = translate_from_resp._id._value\n",
    "\n",
    "    return resp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def normalize_genie(queries: list[str], query_type: str):\n",
    "    # This file contains GENIE Variant queries that we were not able to normalize.\n",
    "    unable_to_normalize_wf = open(f\"unable_to_normalize_{query_type}_queries.csv\", \"w\")\n",
    "    unable_to_normalize_wr = csv.writer(unable_to_normalize_wf, delimiter=\"\\t\")\n",
    "    unable_to_normalize_wr.writerow([\"query\", \"exception_raised\", \"message\", \"warnings\"])\n",
    "\n",
    "    # This file contains GENIE Variant queries that we were able to normalize.\n",
    "    able_to_normalize_wf = open(f\"able_to_normalize_{query_type}_queries.csv\", \"w\")\n",
    "    able_to_normalize_wr = csv.writer(able_to_normalize_wf, delimiter=\"\\t\")\n",
    "    able_to_normalize_wr.writerow([\"query\", \"vrs_id\", \"succeeded_endpoint\"])\n",
    "\n",
    "    for query in tqdm(queries):\n",
    "        try:\n",
    "            variation_norm_resp = await query_handler.normalize_handler.normalize(query, input_assembly=ClinVarAssembly.GRCH37)\n",
    "        except Exception as e:\n",
    "            warnings = [str(e)]\n",
    "\n",
    "            if query_type == \"genomic\":\n",
    "                genomic_resp = translate_from_genomic(query)\n",
    "\n",
    "                if genomic_resp[\"vrs_id\"]:\n",
    "                    vrs_id = genomic_resp[\"vrs_id\"]\n",
    "                else:\n",
    "                    vrs_id = None\n",
    "                    warnings.append(genomic_resp[\"error\"])\n",
    "\n",
    "                if vrs_id:\n",
    "                    able_to_normalize_wr.writerow([query, vrs_id, \"translate_from\"])\n",
    "                    continue\n",
    "            \n",
    "            unable_to_normalize_wr.writerow([query, True, str(e), None])\n",
    "        else:\n",
    "            if variation_norm_resp.variation_descriptor:\n",
    "                vrs_id = variation_norm_resp.variation_descriptor.variation.id\n",
    "                able_to_normalize_wr.writerow([query, vrs_id, \"normalize\"])\n",
    "            else:\n",
    "                if query_type == \"genomic\":\n",
    "                  genomic_resp = translate_from_genomic(query)\n",
    "\n",
    "                    if genomic_resp[\"vrs_id\"]:\n",
    "                        vrs_id = genomic_resp[\"vrs_id\"]\n",
    "                    else:\n",
    "                        vrs_id = None\n",
    "                        warnings.append(genomic_resp[\"error\"])\n",
    "\n",
    "                    if vrs_id:\n",
    "                        able_to_normalize_wr.writerow([query, vrs_id, \"translate_from\"])\n",
    "                        continue\n",
    "\n",
    "                unable_to_normalize_wr.writerow(\n",
    "                    [query, False, \"unable to normalize\", sorted(variation_norm_resp.warnings)]\n",
    "                )\n",
    "\n",
    "    # Close all files\n",
    "    unable_to_normalize_wf.close()\n",
    "    able_to_normalize_wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await normalize_genie(coordinates_df.values, \"genomic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# await normalize_genie(free_text_queries, \"protein\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run cells with existing CSVs\n",
    "\n",
    "This section includes cells to run with existing CSVs. We have this section since normalization takes a long time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column\n",
    "df = pd.read_csv(\"able_to_normalize_genomic_queries.csv\", delimiter=\"\\t\")\n",
    "df[\"succeeded_endpoint\"] = \"normalize\"\n",
    "df.to_csv(\"able_to_normalize_genomic_queries.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unable_to_norm_updated_rows = []\n",
    "\n",
    "with open(\"able_to_normalize_genomic_queries.csv\", \"a\") as a_wf:\n",
    "    d = csv.DictWriter(a_wf, fieldnames=[\"query\", \"vrs_id\", \"succeeded_endpoint\"], delimiter=\"\\t\")\n",
    "    with open(\"unable_to_normalize_genomic_queries.csv\", \"r\") as u_rf:\n",
    "        unable_to_norm = csv.reader(u_rf, delimiter=\"\\t\")\n",
    "        header = next(unable_to_norm)\n",
    "        unable_to_norm_updated_rows.append(header)\n",
    "\n",
    "        for unable_to_norm_row in unable_to_norm:\n",
    "            query, exception_raised, message, warnings = unable_to_norm_row\n",
    "            warnings = eval(warnings)\n",
    "\n",
    "            genomic_resp = translate_from_genomic(query)\n",
    "\n",
    "            if genomic_resp[\"vrs_id\"]:\n",
    "                d.writerow({\"query\": query, \"vrs_id\": genomic_resp[\"vrs_id\"], \"succeeded_endpoint\": \"translate_from\"})\n",
    "            else:\n",
    "                warnings.append(genomic_resp[\"error\"])\n",
    "                unable_to_norm_updated_rows.append([query, exception_raised, message, warnings])\n",
    "\n",
    "\n",
    "with open(\"unable_to_normalize_genomic_queries.csv\", \"a\") as f:\n",
    "    wr = csv.writer(f, delimiter=\"\\t\")\n",
    "    wr.writerows(unable_to_norm_updated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
